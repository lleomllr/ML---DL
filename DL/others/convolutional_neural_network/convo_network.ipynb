{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTxDWc0JF3k8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "import pickle\n",
        "\n",
        "#Charge les données de training\n",
        "X = pickle.load(open(\"X.pickle\", \"rb\"))\n",
        "y = pickle.load(open(\"y.pickle\", \"rb\"))\n",
        "\n",
        "#normalise les données en mettant les valeurs des pixels entre 0 et 1\n",
        "X = X/255.0\n",
        "\n",
        "#Initialise modèle de réseau de neurones séquentiel = pile linéaire de couches\n",
        "model = Sequential()\n",
        "#ajout d'une couche de convolution avec 64 filtres de taille 3x3\n",
        "model.add(Conv2D(64, (3,3), input_shape = X.shape[1:]))\n",
        "#ajout d'une fonction d'activation ReLu, intrdouit la non-linéarité dans le modèle. Transforme val negatives en 0\n",
        "model.add(Activation(\"relu\"))\n",
        "#ajout couche de pooling max qui réduit la dimension spatiale de l'entrée de moitié => Reduit le nb de paramètres\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (3,3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#aplati la sortie des couches en un vect 1D. Passe de la partie convolutionnelle à la connectée\n",
        "model.add(Flatten())\n",
        "#ajout d'une couche dense avec 64 neurones\n",
        "model.add(Dense(64))\n",
        "\n",
        "#ajout d'une couche dense finale avec 1 seule neurone qui sera la sortie du modèle\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"adam\",\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X, y, batch_size=32, epochs = 10, validation_split=0.1)"
      ]
    }
  ]
}