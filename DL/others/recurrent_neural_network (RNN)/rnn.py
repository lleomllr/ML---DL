# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FXa82WiU-tqvjWbspZAZzvpwb3Q1U3Jd
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM

mnist = tf.keras.datasets.mnist
#charge les données et les split en ens d'entrainement
(x_train, y_train),(x_test, y_test) = mnist.load_data()

#normalisation des valeurs de pixels pour les mettre entre 0 et 1
x_train = x_train/255.0
x_test = x_test/255.0

print(x_train.shape)
print(x_train[0].shape)

model = Sequential()
model.add(LSTM(128, input_shape=(x_train.shape[1:]), activation='relu', return_sequences=True))
model.add(Dropout(0.2))

model.add(LSTM(128, activation='relu'))
model.add(Dropout(0.1))

model.add(Dense(32, activation='relu'))
model.add(Dropout(0.2))

model.add(Dense(10, activation='softmax'))

#création d'optimiseur Adam avec taux d'apprentissage de 0.001 et une légère décroissance du taux d'apprentissage de 1e-6
opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.001, decay=1e-6)

model.compile(
    #perte appropriée pour la classification multicatégorie lorsque les étiquettes sont des entiers
    loss='sparse_categorical_crossentropy',
    optimizer=opt,
    metrics=['accuracy'],
)

model.fit(x_train,
          y_train,
          epochs=3,
          validation_data=(x_test, y_test))