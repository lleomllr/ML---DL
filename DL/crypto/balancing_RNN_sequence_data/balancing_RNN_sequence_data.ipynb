{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsuxRigeghdg",
        "outputId": "7fe3a62e-6baa-46a2-b449-584a9f308a65"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import deque\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "SEQ_LEN = 60  #longueur des séquences à utiliser pour chaque échantillon de données\n",
        "FUTURE_PERIOD_PREDICT = 3  #periode future à prédire\n",
        "RATIO_TO_PREDICT = \"LTC-USD\" #crypto à prédire\n",
        "\n",
        "\n",
        "def classify(current, future):\n",
        "  #si val future > val actuelle\n",
        "    if float(future) > float(current):\n",
        "        return 1 #prédire un achat\n",
        "    else:\n",
        "        return 0 #prédire une vente\n",
        "\n",
        "def preprocess_df(df):\n",
        "    df = df.drop(\"future\", axis=1)  #supp colonne 'future' qui était temporaire\n",
        "\n",
        "    for col in df.columns:\n",
        "        if col != \"target\":\n",
        "            df[col] = df[col].pct_change() #calcul le % de changement\n",
        "            df.dropna(inplace=True)\n",
        "            df[col] = preprocessing.scale(df[col].values) #mise à l'échelle des valeurs\n",
        "\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    sequential_data = []  #init liste pour les données séquentielles\n",
        "    prev_days = deque(maxlen=SEQ_LEN) #utilisation deque pour garder les dernières valeurs\n",
        "\n",
        "    for i in df.values:\n",
        "        prev_days.append([n for n in i[:-1]])\n",
        "        if len(prev_days) == SEQ_LEN:\n",
        "            sequential_data.append([np.array(prev_days), i[-1]])\n",
        "\n",
        "    random.shuffle(sequential_data) #melanger les données séquentielles\n",
        "\n",
        "    buys = []  #liste séquences pour achat\n",
        "    sells = []  #liste séquences pour vente\n",
        "\n",
        "    for seq, target in sequential_data:\n",
        "        if target == 0:  #si la cible est O\n",
        "            sells.append([seq, target])  #ajout à la liste 'sells'\n",
        "        elif target == 1: #si la cible est 1\n",
        "            buys.append([seq, target]) #ajout à la liste 'buys'\n",
        "\n",
        "    random.shuffle(buys)\n",
        "    random.shuffle(sells)\n",
        "\n",
        "    lower = min(len(buys), len(sells)) #determine la taille min des listes 'buys' et 'sells'\n",
        "\n",
        "    buys = buys[:lower]  #tronque la liste 'buys' à cette taille\n",
        "    sells = sells[:lower] #tronque la liste 'sells' à cette taille\n",
        "\n",
        "    sequential_data = buys + sells #concaténation des 2 listes\n",
        "    random.shuffle(sequential_data)\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for seq, target in sequential_data:\n",
        "        X.append(seq) #ajoute la séquence à X\n",
        "        y.append(target)  #ajout de la cible à y\n",
        "    return np.array(X), y\n",
        "\n",
        "main_df = pd.DataFrame()  #création d'un dataframe vide 'main_df'\n",
        "\n",
        "ratios = [\"BTC-USD\", \"LTC-USD\", \"BCH-USD\", \"ETH-USD\"]  #liste des crypto à analyser\n",
        "for ratio in ratios:  #parcourir chaque crypto\n",
        "    print(ratio)\n",
        "    dataset = f'/content/gdrive/My Drive/crypto_data/{ratio}.csv'\n",
        "    df = pd.read_csv(dataset, names=['time', 'low', 'high', 'open', 'close', 'volume'])\n",
        "\n",
        "\n",
        "    df.rename(columns={\"close\": f\"{ratio}_close\", \"volume\": f\"{ratio}_volume\"}, inplace=True) #renommer les colonnes pertinentes\n",
        "\n",
        "    df.set_index(\"time\", inplace=True)\n",
        "    df = df[[f\"{ratio}_close\", f\"{ratio}_volume\"]]  #selectionne uniquement les colonnes de cloture et de volume\n",
        "\n",
        "    if len(main_df) == 0:  #si 1er dataframe\n",
        "        main_df = df #assigner le dataframe initial à main_df\n",
        "    else:\n",
        "        main_df = main_df.join(df) #joindre le nouveau dataframe à main_df\n",
        "\n",
        "main_df.fillna(method=\"ffill\", inplace=True)  #remplir val manquantes\n",
        "main_df.dropna(inplace=True) #supp les lignes avec des val restantes\n",
        "\n",
        "main_df['future'] = main_df[f'{RATIO_TO_PREDICT}_close'].shift(-FUTURE_PERIOD_PREDICT)\n",
        "main_df['target'] = list(map(classify, main_df[f'{RATIO_TO_PREDICT}_close'], main_df['future']))\n",
        "\n",
        "main_df.dropna(inplace=True)\n",
        "\n",
        "times = sorted(main_df.index.values) #obtenir les val d'index triées\n",
        "last_5pct = times[-int(0.05 * len(times))] #déterminer le point de séparation pour les données de validation (5% les + récentes)\n",
        "\n",
        "validation_main_df = main_df[(main_df.index >= last_5pct)] #Sélection des données de validation à partir du point de séparation\n",
        "main_df = main_df[(main_df.index < last_5pct)] #Sélection des données d'entraînement jusqu'au point de séparation\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZZJor7YzBWt",
        "outputId": "8e779656-7c6f-430e-9023-3ac97b1da999"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BTC-USD\n",
            "LTC-USD\n",
            "BCH-USD\n",
            "ETH-USD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, train_y = preprocess_df(main_df)\n",
        "validation_x, validation_y = preprocess_df(validation_main_df)"
      ],
      "metadata": {
        "id": "4slm-Em8z6E_"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"train data: {len(train_x)} validation: {len(validation_x)}\")\n",
        "print(f\"Dont buys: {train_y.count(0)}, buys: {train_y.count(1)}\")\n",
        "print(f\"VALIDATION Dont buys: {validation_y.count(0)}, buys: {validation_y.count(1)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVnG7ZqDz9RC",
        "outputId": "14b7b9a2-f462-4b7a-f1d3-d02f155d1370"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data: 77922 validation: 3860\n",
            "Dont buys: 38961, buys: 38961\n",
            "VALIDATION Dont buys: 1930, buys: 1930\n"
          ]
        }
      ]
    }
  ]
}